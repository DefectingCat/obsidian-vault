# 鼠标拾取

*拾取*指代推断用户点击或触碰了哪个对象的过程。

**射线追踪法**（raycasting）很可能是最常用的方法，其基本原理是：从鼠标处发射一条射线，穿透场景的视椎体，通过计算，找出视锥体中哪些对象与射线相交。

`THREE.Raycaster()` 提供了检查从相机到指定位置是否相交的方法。该实例的 `setFromCamera`
 方法可以从相机可视的任意位置发出一条射线，并根据 `intersectObjects` 检查与指定的节点是否相交。

```tsx
class MousePicker {
  raycaster = new Raycaster();

  pick(
    normalizePosition: { x: number; y: number },
    scene: Scene,
    camera: Camera
  ) {
    this.raycaster.setFromCamera(normalizePosition, camera);
    // Save closet object
    const intersectObjects = this.raycaster.intersectObjects(scene.children);
    return intersectObjects[0]?.object;
  }
}
```

而鼠标拾取的思路就是当鼠标进入到了 canvas 的相机中，我们获取鼠标的位置，并将其传递给 `setFromCamera` 方法，它会返回一系列与该位置射出的射线相交的物体。而我们取第一个，也就是离发出射线最近的物体即可。

## Normalize mouse position

对于鼠标来说，其位置在文档中是二维的，所以我们需要通过 canvas 自身的宽高以及鼠标事件时的位置做一点小小的计算。将其转换为 `setFromCamera` 所需要的坐标。

```tsx
const rect = canvas.getBoundingClientRect();
const pos = {
  x: ((e.clientX - rect.left) * canvas.width) / rect.width,
  y: ((e.clientY - rect.top) * canvas.height) / rect.height,
};
pickPosition.x = (pos.x / canvas.width) * 2 - 1;
pickPosition.y = (pos.y / canvas.height) * -2 + 1; // note we flip Y
```

这个过程称其为 normalize。

而对于非鼠标的控制设备（例如触屏）来说，并不是一直会有鼠标在文档中，此时我们希望停止拾取。我们可以用一个特别的值来表示什么都未选中：

```tsx
pickPosition = {
  x: -Infinity,
  y: -Infinity,
};
```

## 渲染中拾取

通过鼠标事件，我们可以很轻松的获取移动时鼠标的位置。但我们的拾取并不是在鼠标移动是，而是需要在每帧渲染时。在鼠标事件中仅仅保存位置即可。

```tsx
threeWrapper.current?.addEventListener('mousemove', setPickPosition);
threeWrapper.current?.addEventListener('mouseout', clearPickPosition);
threeWrapper.current?.addEventListener('mouseleve', clearPickPosition);
```

实际的拾取在渲染中完成，通过实例化简单封装的 `MousePicker` 来在渲染中或离鼠标最近距离的目标：

```tsx
lastObject = mousePicker.pick(pickPosition, three.scene, three.camera);
```

在对目标经过一些简单的检查后，就可以对获取到目标进行实际的操作了：

```tsx
if (!lastObject) return;
if (!(lastObject instanceof THREE.Mesh)) return;
if (!mousePicker.checkMaterial(lastObject.material)) return;
lastColor = lastObject.material.emissive.getHex();
lastObject.material.emissive.setHex(
  (time * 8) % 2 > 1 ? 0xffff00 : 0xff0000
);
```

这个例子中，我们通过 `requestAnimationFrame` 回调中的 `DOMHighResTimeStamp` 参数来设置拾取到的物体的颜色，来实现闪烁。

```tsx
(time * 8) % 2 > 1 ? 0xffff00 : 0xff0000
```

同时在每次拾取开始前，还要对上次的拾取目标进行清理：

```tsx
if (lastObject && lastColor != null) {
  if (!(lastObject instanceof THREE.Mesh)) return;
  if (!mousePicker.checkMaterial(lastObject.material)) return;
  lastObject.material.emissive.setHex(lastColor);
  lastObject = null;
  lastColor = null;
}
```

这种方式看起来效果不错，而且能处理很多用户场景，但是也存在几个问题：

1. 这是基于 CPU 运算的 Javascript 遍历每一个对象，检查其包围盒或包围球是否与射线相交，如果相交，它必须遍历组成该对象的每一个三角，检查它们是否与射线相交。好处是，JavaScript 能够很容易计算出射线在哪里与三角相交，并为我们提供相关数据。举个例子，如果你想要在相交的位置放置一个标记。缺点是，CPU 要做大量的工作,当你的对象由大量的三角组成时，这个过程会有些慢。
2. 它无法处理一些奇怪的着色器或者位移 如果，你有一个变形或者拟态几何形状的着色器，Javascript 无法理解这个变形，它会给出错误的答案。举例：据我所知，你不能对有皮肤的对象使用这种方式。
3. 无法处理透明的孔洞。

## 通过 GPU 拾取

上述方法是通过基于 CPU 的 JavaScript 来遍历每个对象，检查其是否与射线相交。好处是它实现起来非常容易。但伴随的坏处也有很多，其中基于 CPU 的大量运算就是其一，且它无法处理透明的物体。

我们来为立方体添加一些透明，使其成为中空的立方体。

```tsx
const loader = new THREE.TextureLoader();
const texture = loader.load(frame);

const material = new THREE.MeshStandardMaterial({
  color: randomColor(),
  map: texture,
  transparent: true,
  side: THREE.DoubleSide,
  alphaTest: 0.1,
});
```

此时我们继续通过 CPU 来拾取对象，就会发现我们无法穿过立方体的空心从而拾取到在后面的立方体。

这是因为 JavaScript 无法通过简单的查看纹理和材质，就推测出我们的对象是否存在一部分是透明的或者不透明。

![Untitled](%E9%BC%A0%E6%A0%87%E6%8B%BE%E5%8F%96%2003eaa38806a74b1599e2d8d0d449af7f/Untitled.png)

为了完成 GPU 拾取，需要对每一个对象使用唯一的颜色进行离屏渲染。然后，检查鼠标位置关联的像素的颜色。这个颜色就能告诉我们哪个对象被选中。

这能解决上面的问题 2，3。至于问题 1 的速度问题，这取决于业务场景。每个对象会被绘制两次，一次用于观看，一次用于拾取。

但是有一件事值得去做，因为拾取时我们只需读取 1px，所以我们可以设置摄像机，只绘制 1px，通过 `[PerspectiveCamera.setViewOffset](https://threejs.org/docs/#api/zh/cameras/PerspectiveCamera.setViewOffset)` 方法，可以告诉 three.js 计算出一个摄像机 只呈现一个大矩形的一个很小的部分。这应该能节省一些运行时间。

此时，要在 three.js 中实现这种拾取方式，需要创建两个场景。一个使用正常的网格对象填充。另外一个使用“拾取材质”的网格对象填充。